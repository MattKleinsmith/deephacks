{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Goal\n",
    "\n",
    "`f(image, class_id, effect_id) --> image_with_effect_on_class_segments`\n",
    "\n",
    "```python\n",
    "def f1(image, class_id, effect_id):\n",
    "    \"\"\"One way to implement f\"\"\"\n",
    "    image_with_global_effect = apply_effect_to_entire_image(image, effect_id)\n",
    "    local_region = get_local_region(image, class_id)\n",
    "    image_with_local_effect = apply_effect_to_subimage(image,\n",
    "                                                       image_with_global_effect,\n",
    "                                                       local_region)\n",
    "    return image_with_local_effect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "    # V1: Trained on Net 20k, 288x288, black borders, JH's cropped Van Gogh image\n",
    "        # Training:\n",
    "            # lr=1e-3, batch_size=8, nb_epoch=2\n",
    "            # lr=1e-4, batch_size=16, nb_epoch=1\n",
    "        # Try with more images\n",
    "        # Try with bigger images\n",
    "        # Try with center cropping instead\n",
    "        # Try a different training procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Change this to your deephacks repo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/nbs/deephacks/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Low-level functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Stdlib imports\n",
    "from io import BytesIO\n",
    "\n",
    "# Third-party libraries\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "from skimage import data, filters, io, img_as_float\n",
    "import numpy as np\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, cols=1, interp=None, titles=None, cmap=None):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = fig.add_subplot(rows, cols, i+1)\n",
    "        interp_i = interp[i] if interp else None\n",
    "        if titles: sp.set_title(titles[i], fontsize=18)\n",
    "        cmap_i = cmap[i] if cmap else None\n",
    "        plt.imshow(ims[i], interpolation=interp, cmap=cmap_i)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Segmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython import embed\n",
    "from model import get_frontend, add_softmax, add_context\n",
    "from utils import interp_map, pascal_palette\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "ZOOM = 8\n",
    "MEAN = [102.93, 111.36, 116.52]\n",
    "PASCAL_PALETTE = {\n",
    "    0: (0, 0, 0),\n",
    "    1: (128, 0, 0),\n",
    "    2: (0, 128, 0),\n",
    "    3: (128, 128, 0),\n",
    "    4: (0, 0, 128),\n",
    "    5: (128, 0, 128),\n",
    "    6: (0, 128, 128),\n",
    "    7: (128, 128, 128),\n",
    "    8: (64, 0, 0),\n",
    "    9: (192, 0, 0),\n",
    "    10: (64, 128, 0),\n",
    "    11: (192, 128, 0),\n",
    "    12: (64, 0, 128),\n",
    "    13: (192, 0, 128),\n",
    "    14: (64, 128, 128),\n",
    "    15: (192, 128, 128),\n",
    "    16: (0, 64, 0),\n",
    "    17: (128, 64, 0),\n",
    "    18: (0, 192, 0),\n",
    "    19: (128, 192, 0),\n",
    "    20: (0, 64, 128),\n",
    "}\n",
    "\n",
    "CATEGORIES = {\n",
    "        'aeroplane': 1,\n",
    "        'bicycle': 2,\n",
    "        'bird': 3,\n",
    "        'boat': 4,\n",
    "        'bottle': 5,\n",
    "        'bus': 6,\n",
    "        'car': 7,\n",
    "        'cat': 8,\n",
    "        'chair': 9,\n",
    "        'cow': 10,\n",
    "        'diningtable': 11,\n",
    "        'dog': 12,\n",
    "        'horse': 13,\n",
    "        'motorbike': 14,\n",
    "        'person': 15,\n",
    "        'pottedplant': 16,\n",
    "        'sheep': 17,\n",
    "        'sofa': 18,\n",
    "        'train': 19,\n",
    "        'tvmonitor': 20\n",
    "}\n",
    "\n",
    "# Settings for the Pascal dataset\n",
    "input_width, input_height = 900, 900\n",
    "label_margin = 186\n",
    "has_context_module = False\n",
    "\n",
    "def get_trained_model():\n",
    "    \"\"\" Returns a model with loaded weights. \"\"\"\n",
    "\n",
    "    model = get_frontend(input_width, input_height)\n",
    "\n",
    "    if has_context_module:\n",
    "        model = add_context(model)\n",
    "\n",
    "    model = add_softmax(model)\n",
    "\n",
    "    def load_tf_weights():\n",
    "        \"\"\" Load pretrained weights converted from Caffe to TF. \"\"\"\n",
    "\n",
    "        # 'latin1' enables loading .npy files created with python2\n",
    "        weights_data = np.load(SEGMENTATION_WEIGHTS_PATH, encoding='latin1').item()\n",
    "\n",
    "        for layer in model.layers:\n",
    "            if layer.name in weights_data.keys():\n",
    "                layer_weights = weights_data[layer.name]\n",
    "                layer.set_weights((layer_weights['weights'],\n",
    "                                   layer_weights['biases']))\n",
    "\n",
    "    def load_keras_weights():\n",
    "        \"\"\" Load a Keras checkpoint. \"\"\"\n",
    "        model.load_weights(SEGMENTATION_WEIGHTS_PATH)\n",
    "\n",
    "    if SEGMENTATION_WEIGHTS_PATH.endswith('.npy'):\n",
    "        load_tf_weights()\n",
    "    elif SEGMENTATION_WEIGHTS_PATH.endswith('.hdf5'):\n",
    "        load_keras_weights()\n",
    "    else:\n",
    "        raise Exception(\"Unknown weights format.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def forward_pass(image):\n",
    "    ''' Runs a forward pass to segment the image. '''\n",
    "\n",
    "    model = get_trained_model()\n",
    "\n",
    "    # Load image and swap RGB -> BGR to match the trained weights\n",
    "    image_rgb = image.astype(np.float32)\n",
    "    image = image_rgb[:, :, ::-1] - MEAN\n",
    "    image_size = image.shape\n",
    "\n",
    "    # Network input shape (batch_size=1)\n",
    "    net_in = np.zeros((1, input_height, input_width, 3), dtype=np.float32)\n",
    "\n",
    "    output_height = input_height - 2 * label_margin\n",
    "    output_width = input_width - 2 * label_margin\n",
    "\n",
    "    # This simplified prediction code is correct only if the output\n",
    "    # size is large enough to cover the input without tiling\n",
    "    try:\n",
    "        assert image_size[0] < output_height\n",
    "        assert image_size[1] < output_width\n",
    "    except:\n",
    "        print(\"Max output hight and width:\", output_height-1, output_width-1)\n",
    "        print(\"Current output_height and output_width\", image_size)\n",
    "        raise Exception(\"Assertion error\")\n",
    "\n",
    "    # Center pad the original image by label_margin.\n",
    "    # This initial pad adds the context required for the prediction\n",
    "    # according to the preprocessing during training.\n",
    "    image = np.pad(image,\n",
    "                   ((label_margin, label_margin),\n",
    "                    (label_margin, label_margin),\n",
    "                    (0, 0)), 'reflect')\n",
    "\n",
    "    # Add the remaining margin to fill the network input width. This\n",
    "    # time the image is aligned to the upper left corner though.\n",
    "    margins_h = (0, input_height - image.shape[0])\n",
    "    margins_w = (0, input_width - image.shape[1])\n",
    "    image = np.pad(image,\n",
    "                   (margins_h,\n",
    "                    margins_w,\n",
    "                    (0, 0)), 'reflect')\n",
    "\n",
    "    # Run inference\n",
    "    net_in[0] = image\n",
    "    prob = model.predict(net_in)[0]\n",
    "\n",
    "    # Reshape to 2d here since the networks outputs a flat array per channel\n",
    "    prob_edge = np.sqrt(prob.shape[0]).astype(np.int)\n",
    "    prob = prob.reshape((prob_edge, prob_edge, 21))\n",
    "\n",
    "    # Upsample\n",
    "    if ZOOM > 1:\n",
    "        prob = interp_map(prob, ZOOM, image_size[1], image_size[0])\n",
    "\n",
    "    # Recover the most likely prediction (actual segment class)\n",
    "    prediction = np.argmax(prob, axis=2)\n",
    "    # Apply the color palette to the segmented image\n",
    "    color_image = np.array(pascal_palette)[prediction.ravel()].reshape(\n",
    "        prediction.shape + (3,))\n",
    "    return prediction, color_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Style transfer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8675309)\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Input, InputSpec, Lambda, Convolution2D, BatchNormalization, Activation, UpSampling2D, merge\n",
    "import keras.backend as K\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "        \n",
    "    def get_output_shape_for(self, s):\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "    \n",
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Convolution2D(filters, size, size, subsample=stride, border_mode=mode)(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_crop_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, (1,1), 'valid')\n",
    "    x = conv_block(x,  nf, 3, (1,1), 'valid', False)\n",
    "    ip = Lambda(lambda x: x[:, 2:-2, 2:-2])(ip)\n",
    "    return merge([x, ip], mode='sum')\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Convolution2D(filters, size, size, border_mode='same')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def make_mixer(mixer_input):\n",
    "    c = 2 # Number of conv blocks and up blocks\n",
    "    r = 5 # Number of res blocks\n",
    "    r2 = r * 8 # Amount of reflection padding\n",
    "    nf = 64\n",
    "    x = ReflectionPadding2D((r2, r2))(mixer_input)\n",
    "    x = conv_block(x, nf, 9, (1,1))\n",
    "    for i in range(c): x = conv_block(x, nf, 3)\n",
    "    for i in range(r): x = res_crop_block(x, nf)\n",
    "    for i in range(c): x = up_block(x, nf, 3)\n",
    "    x = Convolution2D(3, 9, 9, activation='tanh', border_mode='same')(x)\n",
    "    mixer_output = Lambda(lambda x: (x+1)*127.5)(x)\n",
    "    return Model(mixer_input, mixer_output, name=\"mixer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Medium-level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_mixer(shape, effect_id=\"van_gogh\", version=\"1\"):\n",
    "    weights_dir = WEIGHTS_DIR + effect_id + \"/\"\n",
    "    mixer_input = Input(shape, name=\"mixer_input\")\n",
    "    mixer = make_mixer(mixer_input)\n",
    "    mixer.load_weights(weights_dir + f'v{version}.h5')\n",
    "    return mixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### High-level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "from scipy.misc import imsave\n",
    "from time import time\n",
    "    \n",
    "def show_results(image, class_id, effect_id=\"van_gogh\", foreground=True, opacity=0.80, blur=True):\n",
    "    \"\"\"The highest level function.\"\"\"\n",
    "    parameters = ['', TEST_PHOTO_FILENAME, effect_id, class_id, str(foreground), str(opacity)]\n",
    "    results_path = OUTPUT_PREFIX + '_'.join(parameters) + \".png\"\n",
    "    try:\n",
    "        result = np.array(Image.open(results_path))\n",
    "    except:\n",
    "        start = time()\n",
    "        image = np.array(image)\n",
    "        start_1 = time()\n",
    "        try:\n",
    "            mask = np.array(Image.open(MASK_FILE))\n",
    "        except IOError:\n",
    "            mask = get_local_region(image, class_id)\n",
    "        #print(\"get_local_region:\", time() - start_1, \"seconds\")\n",
    "        start_2 = time()\n",
    "        stylized_global = apply_effect_to_entire_image(image, effect_id)[0]\n",
    "        #print(\"apply_effect_to_entire_image:\", time() - start_2, \"seconds\")\n",
    "        start_3 = time()\n",
    "        result = apply_effect_to_subimage(image, stylized_global, mask, foreground, opacity, blur)\n",
    "        #print(\"apply_effect_to_subimage:\", time() - start_3, \"seconds\")\n",
    "        # Save\n",
    "        start_4 = time()\n",
    "        imsave(results_path, result)\n",
    "        print(\"Saving!: \", results_path)\n",
    "        #print(\"imsave:\", time() - start_4, \"seconds\")\n",
    "        #print(\"Saved to:\", results_file)\n",
    "        # Plots\n",
    "        imgs = [image, stylized_global, mask]\n",
    "        #plots(imgs, figsize=(12, 12), rows=1, cols=3, cmap=[None, None, \"gray\"])\n",
    "        #plots([result], figsize=(8, 8), rows=1, cols=1);\n",
    "        #print(\"show_results:\", time() - start)\n",
    "    return result\n",
    "\n",
    "def get_local_region(image, class_id):\n",
    "    # Get segments of all classes\n",
    "    pred, color_image = forward_pass(image)\n",
    "    #Change all pixels != our target category to 0 (black)\n",
    "    pred[pred != CATEGORIES[class_id]] = 0\n",
    "    #Change all pixels == our target category to 1 (white)\n",
    "    pred[pred == CATEGORIES[class_id]] = 255\n",
    "    # Save image locally\n",
    "    imsave(MASK_FILE, pred)\n",
    "    print('Saved to:', MASK_FILE)\n",
    "    return pred\n",
    "    \n",
    "def apply_effect_to_entire_image(images, effect_id=\"van_gogh\"):\n",
    "    \"\"\"Applies an effect to a list of images.\"\"\"\n",
    "    if type(images) == list:\n",
    "        images = np.array(images)\n",
    "    elif type(images) == np.ndarray and len(images.shape) < 4:\n",
    "        images = np.expand_dims(images, 0)\n",
    "    shape = images[0].shape\n",
    "    if effect_id in [\"van_gogh\", \"scream\", \"okeffe\"]:\n",
    "        mixer = load_mixer(shape, effect_id, version=\"1\")\n",
    "        raw_results = mixer.predict(images)\n",
    "        images_with_global_effect = [np.round(raw_result).astype('uint8') for raw_result in raw_results]\n",
    "    elif effect_id == \"black\":\n",
    "        images_with_global_effect = [np.zeros(shape).astype('uint8')]\n",
    "    elif effect_id == \"white\":\n",
    "        full = np.ones(shape)\n",
    "        full.fill(255)\n",
    "        images_with_global_effect = [full.astype('uint8')]\n",
    "    else:\n",
    "        img_pil = Image.fromarray(images[0])\n",
    "        if effect_id == \"blur\":\n",
    "            images_with_global_effect = [np.array(img_pil.filter(ImageFilter.BLUR)).astype('uint8')]\n",
    "        elif effect_id == \"blur50\":\n",
    "            images_with_global_effect = [np.array(img_pil.filter(ImageFilter.GaussianBlur(radius=50))).astype('uint8')]\n",
    "        elif effect_id == \"blur25\":\n",
    "            images_with_global_effect = [np.array(img_pil.filter(ImageFilter.GaussianBlur(radius=25))).astype('uint8')]\n",
    "        elif effect_id == \"blur12\":\n",
    "            images_with_global_effect = [np.array(img_pil.filter(ImageFilter.GaussianBlur(radius=12))).astype('uint8')]\n",
    "    return images_with_global_effect\n",
    "    \n",
    "def apply_effect_to_subimage(image, image_with_global_effect, mask, foreground, opacity, blur):\n",
    "    pil_mask = Image.fromarray(mask.astype('uint8'))\n",
    "    if blur:\n",
    "        pil_mask = pil_mask.filter(ImageFilter.BLUR)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    pil_image_with_global_effect = Image.fromarray(image_with_global_effect)\n",
    "    if pil_image_with_global_effect.size != pil_image.size:\n",
    "        print(\"Error: Image size mismatch?\")\n",
    "        print(\"Sizes:\", pil_image_with_global_effect.size, pil_image.size, pil_mask.size)\n",
    "        print(\"######### Forcing a resize.\")\n",
    "        pil_image_with_global_effect = pil_image_with_global_effect.resize(pil_image.size)\n",
    "    if pil_image.size != pil_mask.size:\n",
    "        print(\"Deleting cached mask file:\", MASK_FILE)\n",
    "        os.remove(MASK_FILE) # In case someone changed the size of their image\n",
    "    if foreground:\n",
    "        final_image = Image.composite(pil_image_with_global_effect, pil_image, pil_mask)\n",
    "    else:\n",
    "        final_image = Image.composite(pil_image, pil_image_with_global_effect, pil_mask)\n",
    "    final_image = Image.blend(pil_image, final_image, opacity)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Highest-level API so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stdlib imports\n",
    "from io import BytesIO\n",
    "\n",
    "# Third-party libraries\n",
    "from IPython.display import Image as IImage\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib as mpl\n",
    "from skimage import data, filters, io, img_as_float\n",
    "import numpy as np\n",
    "\n",
    "def arr2img(arr):\n",
    "    \"\"\"Display a 2- or 3-d numpy array as an image.\"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        format, cmap = 'png', mpl.cm.gray\n",
    "    elif arr.ndim == 3:\n",
    "        format, cmap = 'jpg', None\n",
    "    else:\n",
    "        raise ValueError(\"Only 2- or 3-d arrays can be displayed as images.\")\n",
    "    # Don't let matplotlib autoscale the color range so we can control overall luminosity\n",
    "    vmax = 255 if arr.dtype == 'uint8' else 1.0\n",
    "    with BytesIO() as buffer:\n",
    "        mpl.image.imsave(buffer, arr, format=format, cmap=cmap, vmin=0, vmax=vmax)\n",
    "        out = buffer.getvalue()\n",
    "    return IImage(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f(opacity, foreground, effect_id, class_id):\n",
    "    global MASK_FILE\n",
    "    MASK_FILE = OUTPUT_DIR + TEST_PHOTO_FILENAME + '_seg_' + class_id + '.png'\n",
    "    image = Image.open(INPUT_FILE)\n",
    "    image_pil = show_results(image, class_id=class_id, effect_id=effect_id, foreground=foreground, opacity=opacity)\n",
    "    image_np = np.array(image_pil)\n",
    "    return arr2img(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def supercharge(input_file, class_id):\n",
    "    global MASK_FILE\n",
    "    MASK_FILE = OUTPUT_DIR + TEST_PHOTO_FILENAME + '_seg_' + class_id + '.png'\n",
    "    start = time()\n",
    "    image = Image.open(input_file)\n",
    "    for opacity in range(0, 110, 10):\n",
    "        opacity = opacity / 100\n",
    "        for foreground in [True, False]:\n",
    "            for effect_id in [style for style in STYLES if style != \"scream\"]:\n",
    "                image_pil = show_results(image, class_id=class_id,\n",
    "                                         effect_id=effect_id, foreground=foreground, opacity=opacity)\n",
    "    print(\"Supercharging took %.2f seconds\" % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "STYLES = [\"van_gogh\", \"scream\", \"okeffe\", \"black\", \"white\", \"blur50\", \"blur25\", \"blur12\", \"blur\"]\n",
    "\n",
    "WEIGHTS_DIR = INPUT_DIR + \"weights/\"\n",
    "SEGMENTATION_WEIGHTS_PATH = INPUT_DIR + 'conversion/dilation8_pascal_voc.npy'\n",
    "\n",
    "RESULTS_DIR = INPUT_DIR + 'results/'\n",
    "IMAGES_DIR = 'images/'\n",
    "OUTPUT_DIR = IMAGES_DIR + 'segmentations/'\n",
    "\n",
    "TEST_PHOTO_FILENAME = 'images/2008_003888.jpg'.split(IMAGES_DIR)[-1]\n",
    "\n",
    "INPUT_FILE = IMAGES_DIR + TEST_PHOTO_FILENAME\n",
    "OUTPUT_PREFIX = RESULTS_DIR + TEST_PHOTO_FILENAME.split('.')[0]\n",
    "\n",
    "opacity_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.10, value=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "interact(f, class_id=CATEGORIES.keys(), effect_id=STYLES, foreground=True, opacity=opacity_slider);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
