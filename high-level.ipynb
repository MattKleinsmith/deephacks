{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Goal\n",
    "\n",
    "`f(image, class_id, effect_id) --> image_with_effect_on_class_segments`\n",
    "\n",
    "```python\n",
    "def f1(image, class_id, effect_id):\n",
    "    \"\"\"One way to implement f\"\"\"\n",
    "    image_with_global_effect = apply_effect_to_entire_image(image, effect_id)\n",
    "    local_region = get_local_region(image, class_id)\n",
    "    image_with_local_effect = apply_effect_to_subimage(image,\n",
    "                                                       image_with_global_effect,\n",
    "                                                       local_region)\n",
    "    return image_with_local_effect\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "    # V1: Trained on ImageNet 20k, 288x288, black borders, JH's cropped Van Gogh image\n",
    "        # Training:\n",
    "            # lr=1e-3, batch_size=8, nb_epoch=2\n",
    "            # lr=1e-4, batch_size=16, nb_epoch=1\n",
    "        # Try with more images\n",
    "        # Try with bigger images\n",
    "        # Try with center cropping instead\n",
    "        # Try a different training procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change this to your deephacks repo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = '/nbs/deephacks/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHTS_DIR = INPUT_DIR + \"weights/\"\n",
    "SEGMENTATION_WEIGHTS_PATH = INPUT_DIR + 'conversion/dilation8_pascal_voc.npy'\n",
    "\n",
    "RESULTS_DIR = INPUT_DIR+'results/'\n",
    "OUTPUT_DIR = 'images/segmentations/'\n",
    "IMAGES_DIR = 'images/'\n",
    "\n",
    "TEST_PHOTO_FILENAME = 'cat.jpg'\n",
    "\n",
    "INPUT_FILE = IMAGES_DIR + TEST_PHOTO_FILENAME\n",
    "MASK_FILE = OUTPUT_DIR + TEST_PHOTO_FILENAME+'_seg.png'\n",
    "OUTPUT_FILE = RESULTS_DIR+TEST_PHOTO_FILENAME+'_stylized.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Low-level functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plots(ims, figsize=(12,6), rows=1, cols=1, interp=None, titles=None, cmap=None):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = fig.add_subplot(rows, cols, i+1)\n",
    "        if titles:\n",
    "            sp.set_title(titles[i], fontsize=18)\n",
    "        plt.imshow(ims[i], interpolation=interp, cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from scipy.misc import imsave\n",
    "def show_results(image, mask, output_filename, effect_id=\"van_gogh\"):\n",
    "    image = deepcopy(image)\n",
    "    stylized_global = apply_effect_to_entire_image(image, effect_id=effect_id)[0]\n",
    "    imgs = [image, mask, stylized_global]\n",
    "    plots(imgs, figsize=(12, 12), rows=1, cols=3)\n",
    "    result = apply_effect_to_subimage(image, stylized_global, mask, offset=3)\n",
    "    imsave(output_filename, result)\n",
    "    plots([result], figsize=(8, 8), rows=1, cols=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Style transfer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(8675309)\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Input, InputSpec, Lambda, Convolution2D, BatchNormalization, Activation, UpSampling2D, merge\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "\n",
    "class ReflectionPadding2D(Layer):\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "        \n",
    "    def get_output_shape_for(self, s):\n",
    "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        w_pad,h_pad = self.padding\n",
    "        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')\n",
    "    \n",
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Convolution2D(filters, size, size, subsample=stride, border_mode=mode)(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_crop_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, (1,1), 'valid')\n",
    "    x = conv_block(x,  nf, 3, (1,1), 'valid', False)\n",
    "    ip = Lambda(lambda x: x[:, 2:-2, 2:-2])(ip)\n",
    "    return merge([x, ip], mode='sum')\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Convolution2D(filters, size, size, border_mode='same')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def make_mixer(mixer_input):\n",
    "    c = 2 # Number of conv blocks and up blocks\n",
    "    r = 5 # Number of res blocks\n",
    "    r2 = r * 8 # Amount of reflection padding\n",
    "    nf = 64\n",
    "    x = ReflectionPadding2D((r2, r2))(mixer_input)\n",
    "    x = conv_block(x, nf, 9, (1,1))\n",
    "    for i in range(c): x = conv_block(x, nf, 3)\n",
    "    for i in range(r): x = res_crop_block(x, nf)\n",
    "    for i in range(c): x = up_block(x, nf, 3)\n",
    "    x = Convolution2D(3, 9, 9, activation='tanh', border_mode='same')(x)\n",
    "    mixer_output = Lambda(lambda x: (x+1)*127.5)(x)\n",
    "    return Model(mixer_input, mixer_output, name=\"mixer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Medium-level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_mixer(shape, version=\"1\"):\n",
    "    weights_dir = WEIGHTS_DIR + \"van_gogh/\"\n",
    "    mixer_input = Input(shape, name=\"mixer_input\")\n",
    "    mixer = make_mixer(mixer_input)\n",
    "    mixer.load_weights(weights_dir + f'v{version}.h5')\n",
    "    return mixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### High-level functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def f1(image, class_id, effect_id):\n",
    "    \"\"\"One way to implement f\n",
    "    The highest level function\"\"\"\n",
    "    image_with_global_effect = apply_effect_to_entire_image(image, effect_id)\n",
    "    local_region = get_local_region(image, class_id)\n",
    "    image_with_local_effect = apply_effect_to_subimage(image,\n",
    "                                                       image_with_global_effect,\n",
    "                                                       local_region)\n",
    "    return image_with_local_effect\n",
    "\n",
    "def get_local_region(image, class_id):\n",
    "    \"\"\"Matthew is covering this.\"\"\"\n",
    "    # load segmentation network\n",
    "    # get segmentation (i.e. mask, i.e. local region)\n",
    "    return local_region\n",
    "    \n",
    "def apply_effect_to_entire_image(images, effect_id=\"van_gogh\"):\n",
    "    \"\"\"Applies an effect to a list of images.\n",
    "    Matthew is covering this.\"\"\"\n",
    "    if type(images) == list:\n",
    "        images = np.array(images)\n",
    "    elif type(images) == np.ndarray and len(images.shape) < 4:\n",
    "        images = np.expand_dims(images, 0)\n",
    "    shape = images[0].shape\n",
    "    if effect_id == \"van_gogh\":\n",
    "        mixer = load_mixer(shape, version=\"1\")\n",
    "        raw_results = mixer.predict(images)\n",
    "        images_with_global_effect = [np.round(raw_result).astype('uint8') for raw_result in raw_results]\n",
    "    if effect_id == \"black\":\n",
    "        images_with_global_effect = [np.zeros(shape)]\n",
    "    return images_with_global_effect\n",
    "    \n",
    "def apply_effect_to_subimage(image, image_with_global_effect, mask, offset):\n",
    "    width, height, channels = image_with_global_effect.shape\n",
    "    for i in range(width-offset):\n",
    "        for j in range(height-offset):\n",
    "            if mask[i, j] == 255:\n",
    "                image[i, j, :] = image_with_global_effect[i, j, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest-level API so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = np.array(Image.open(INPUT_FILE))\n",
    "mask = np.array(Image.open(MASK_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_results(image, mask, OUTPUT_FILE+\"_van_gogh.png\", effect_id=\"van_gogh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_results(image, mask, OUTPUT_FILE+\"_black.png\", effect_id=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
